{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ducha-1504/AISI-project/blob/main/Duc's_Yahoo_Finance_Code_Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount G-drive to save your output\n",
        "# It will promp you to give permission to Google to access your file\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Pandas is a Python library used for working with data sets.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hReZVLngF7xU",
        "outputId": "def0ec2a-9618-484b-f09e-51eee75b3da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import http.client\n",
        "import json\n",
        "import datetime\n",
        "import csv\n",
        "import os\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "D75EQbH0vlii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity API setup\n",
        "API_HOST = \"api.perplexity.ai\"\n",
        "API_ENDPOINT = \"/chat/completions\"\n",
        "API_KEY = \"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\""
      ],
      "metadata": {
        "id": "obd1XhWTv16J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard headers\n",
        "CSV_HEADER = [\"Date\", \"Ticker\", \"Company Name\", \"Sector\", \"Weight\", \"Price Buy\", \"Price Sell\"]\n",
        "\n",
        "# Prompts dictionary (unchanged)\n",
        "prompts = {\n",
        "    \"Market_Direction_Prediction\": \"Today is #TODAY#. Predict the S&P 500 direction for tomorrow. Provide output in CSV:\\nDate,Prediction,Confidence\",\n",
        "    \"Low_Risk_Portfolio\": \"Today is #TODAY#. Pretend to be a financial expert. Construct a low-risk portfolio for the S&P 500. \"\n",
        "                          \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\",\n",
        "    \"High_Risk_Portfolio\": \"Today is #TODAY#. Construct a high-risk portfolio for the S&P 500. \"\n",
        "                           \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\",\n",
        "    \"No_Risk_Specification_Portfolio\": \"Today is #TODAY#. Construct a portfolio designed to outperform the S&P 500. \"\n",
        "                                       \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\",\n",
        "    \"Value_Based_Investing_Portfolio\": \"Today is #TODAY#. Use a value investing strategy to pick 25 S&P 500 stocks. \"\n",
        "                                       \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\",\n",
        "    \"Growth_Based_Investing_Portfolio\": \"Today is #TODAY#. Use a growth investing strategy to pick 25 S&P 500 stocks. \"\n",
        "                                        \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\",\n",
        "    \"Dividend_Based_Investing_Portfolio\": \"Today is #TODAY#. Use a dividend investing strategy to pick 25 S&P 500 stocks. \"\n",
        "                                          \"Provide output in CSV format:\\nDate,Ticker,Company Name,Sector,Weight,Price Buy,Price Sell\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "t0U6IzTIv8NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Perplexity API (unchanged)\n",
        "def query_perplexity(prompt):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"r1-1776\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a financial AI expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    connection = http.client.HTTPSConnection(API_HOST)\n",
        "    connection.request(\"POST\", API_ENDPOINT, body=json.dumps(payload), headers=headers)\n",
        "    response = connection.getresponse()\n",
        "\n",
        "    if response.status == 200:\n",
        "        return response.read().decode(\"utf-8\").strip()\n",
        "    else:\n",
        "        print(f\"Error {response.status}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "9WecIXTQl06L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract CSV from response\n",
        "def extract_csv(response_text):\n",
        "    try:\n",
        "        data = json.loads(response_text)\n",
        "        content = data[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "        csv_start = content.find(\"```csv\")\n",
        "        csv_end = content.rfind(\"```\")\n",
        "\n",
        "        if csv_start != -1 and csv_end != -1:\n",
        "            return content[csv_start + len(\"```csv\"):csv_end].strip()\n",
        "        else:\n",
        "            return None\n",
        "    except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
        "        print(f\"Error parsing response: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "DND71SfomdHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_row(row):\n",
        "    fields = row.split(',')\n",
        "    if len(fields) < 7:\n",
        "        return None\n",
        "    try:\n",
        "        weight_val = float(fields[4].strip().replace('%', ''))\n",
        "        price_buy_val = float(fields[5].strip().replace('$', ''))\n",
        "        price_sell_val = float(fields[6].strip().replace('$', ''))\n",
        "\n",
        "        weight_formatted = f\"{round(weight_val, 2):.2f}%\"\n",
        "        price_buy_formatted = f\"${round(price_buy_val, 2):.2f}\"\n",
        "        price_sell_formatted = f\"${round(price_sell_val, 2):.2f}\"\n",
        "\n",
        "        return fields[:4] + [weight_formatted, price_buy_formatted, price_sell_formatted]\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "6M6qroCnLbWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_latest_10_prices_buy(filename, num_rows=10):\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "\n",
        "        # Only process if we have at least 10 rows\n",
        "        if df.shape[0] < num_rows:\n",
        "            return\n",
        "\n",
        "        latest_df = df.tail(num_rows).copy()\n",
        "        tickers = latest_df['Ticker'].unique().tolist()\n",
        "\n",
        "        # Fetch latest Close prices for tickers\n",
        "        prices = yf.download(tickers=tickers, period=\"1d\", interval=\"1d\", progress=False)[\"Close\"]\n",
        "        if isinstance(prices, pd.Series):  # If single ticker, convert to dict\n",
        "            prices = prices.to_dict()\n",
        "        else:\n",
        "            prices = prices.iloc[-1].to_dict()  # Last available row\n",
        "\n",
        "        # Update latest 10 rows in the main dataframe\n",
        "        for i in latest_df.index:\n",
        "            ticker = df.loc[i, 'Ticker']\n",
        "            if ticker in prices:\n",
        "                price = round(float(prices[ticker]), 2)\n",
        "                df.at[i, 'Price Buy'] = f\"${price:.2f}\"\n",
        "\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"✅ Updated real-time prices in: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating prices in {filename}: {e}\")"
      ],
      "metadata": {
        "id": "-g232LuP3ng9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_latest_10_price_sell(filename, num_rows=10):\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "        if df.shape[0] < num_rows:\n",
        "            return\n",
        "\n",
        "        latest_df = df.tail(num_rows).copy()\n",
        "        tickers = latest_df['Ticker'].unique().tolist()\n",
        "\n",
        "        # Fetch the latest High prices\n",
        "        highs = yf.download(tickers=tickers, period=\"1d\", interval=\"1d\", progress=False)[\"High\"]\n",
        "\n",
        "        if isinstance(highs, pd.Series):\n",
        "            highs = highs.to_dict()\n",
        "        else:\n",
        "            highs = highs.iloc[-1].to_dict()\n",
        "\n",
        "        for i in latest_df.index:\n",
        "            ticker = df.loc[i, 'Ticker']\n",
        "            if ticker in highs:\n",
        "                price = round(float(highs[ticker]), 2)\n",
        "                df.at[i, 'Price Sell'] = f\"${price:.2f}\"\n",
        "\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"✅ Updated real-time 'Price Sell' in: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating Price Sell in {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "MA4PHYp7JYtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def append_to_csv(csv_data, filename):\n",
        "    if not csv_data:\n",
        "        print(f\"No CSV data to write for {filename}\")\n",
        "        return\n",
        "\n",
        "    file_exists = os.path.exists(filename)\n",
        "\n",
        "    lines = csv_data.strip().split('\\n')\n",
        "    header = lines[0]\n",
        "    rows = lines[1:26]\n",
        "    temp_weights = []\n",
        "    temp_data = []\n",
        "\n",
        "    for row in rows:\n",
        "        cleaned = clean_row(row)\n",
        "        if cleaned:\n",
        "            weight_val = float(cleaned[4].replace('%', ''))\n",
        "            temp_weights.append(weight_val)\n",
        "            temp_data.append(cleaned)\n",
        "\n",
        "    total_weight = sum(temp_weights)\n",
        "\n",
        "    normalized_rows = []\n",
        "    for i, row in enumerate(temp_data):\n",
        "      new_weight = (temp_weights[i] / total_weight) * 100\n",
        "      weight_str = f\"{round(new_weight, 2):.2f}%\"\n",
        "      normalized_rows.append(row[:4] + [weight_str, row[5], row[6]])\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            if not file_exists:\n",
        "                writer.writerow(header.split(','))\n",
        "            writer.writerows(normalized_rows)\n",
        "        print(f\" Data appended to {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing to {filename}: {e}\")"
      ],
      "metadata": {
        "id": "PqAqg_8OmyVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def main():\n",
        "    today = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
        "    output_dir = '/content/drive/My Drive/Finance_Portfolios'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    successful_files = []\n",
        "\n",
        "    for key, raw_prompt in prompts.items():\n",
        "        formatted_prompt = raw_prompt.replace(\"#TODAY#\", today)\n",
        "        response = query_perplexity(formatted_prompt)\n",
        "\n",
        "        if response:\n",
        "            csv_text = extract_csv(response)\n",
        "            if csv_text:\n",
        "                filename = f\"/content/drive/My Drive/Finance_Portfolios/{key}.csv\"\n",
        "                append_to_csv(csv_text, filename)\n",
        "            else:\n",
        "                print(f\"Failed to extract CSV for {key}\")\n",
        "        else:\n",
        "            print(f\"API call failed for {key}\")\n",
        "    print(\"\\n⏳ Updating real-time prices...\\n\")\n",
        "    target_file = \"/content/drive/My Drive/Finance_Portfolios/No_Risk_Specification_Portfolio.csv\"\n",
        "    if os.path.exists(target_file):\n",
        "          update_latest_10_prices_buy(target_file, num_rows=10)  # For Price Buy\n",
        "          update_latest_10_price_sell(target_file, num_rows=10)  # For Price Sell\n",
        "    else:\n",
        "      print(\"⚠️ Target portfolio file not found.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GoxwC7eKva7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8561f5-017c-4ac7-9cbf-286b5addaa1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data appended to /content/drive/My Drive/Finance_Portfolios/Market_Direction_Prediction.csv\n",
            " Data appended to /content/drive/My Drive/Finance_Portfolios/Low_Risk_Portfolio.csv\n",
            " Data appended to /content/drive/My Drive/Finance_Portfolios/High_Risk_Portfolio.csv\n",
            " Data appended to /content/drive/My Drive/Finance_Portfolios/No_Risk_Specification_Portfolio.csv\n",
            " Data appended to /content/drive/My Drive/Finance_Portfolios/Value_Based_Investing_Portfolio.csv\n",
            "Failed to extract CSV for Growth_Based_Investing_Portfolio\n",
            " Data appended to /content/drive/My Drive/Finance_Portfolios/Dividend_Based_Investing_Portfolio.csv\n",
            "\n",
            "⏳ Updating real-time prices...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-319915760.py:13: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  prices = yf.download(tickers=tickers, period=\"1d\", interval=\"1d\", progress=False)[\"Close\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated real-time prices in: /content/drive/My Drive/Finance_Portfolios/No_Risk_Specification_Portfolio.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4241283881.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  highs = yf.download(tickers=tickers, period=\"1d\", interval=\"1d\", progress=False)[\"High\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Updated real-time 'Price Sell' in: /content/drive/My Drive/Finance_Portfolios/No_Risk_Specification_Portfolio.csv\n"
          ]
        }
      ]
    }
  ]
}